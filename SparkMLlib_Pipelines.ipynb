{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNiFoLcKvFhqGtkeY61q5KH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tTlPbBDBcnsE","executionInfo":{"status":"ok","timestamp":1691985157418,"user_tz":-480,"elapsed":50531,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"365043a9-a8e4-4879-d3b4-cef57c49dffc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285388 sha256=2e772a6c1e1174ad73e3184bc132cf3193977a5119eb6512e7c8ca5cc2edf91b\n","  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.4.1\n"]}]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","\n","# Create a Spark Session\n","spark = SparkSession.builder\\\n","        .master(\"local[*]\")\\\n","        .appName(\"ML Pipelines Tutorial\")\\\n","        .getOrCreate()\n","\n","spark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"VXcuizcKec45","executionInfo":{"status":"ok","timestamp":1691985188659,"user_tz":-480,"elapsed":11903,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"578f67ec-997b-41fe-8303-a0f903e1250a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7c0c783f8f10>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://76737c2c7d62:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.4.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>ML Pipelines Tutorial</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["spark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"lS0Z4Ih3-jZO","executionInfo":{"status":"ok","timestamp":1691998635101,"user_tz":-480,"elapsed":546,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"51d4f758-c6b9-41c5-8ed1-cfdf33322564"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7c0c783f8f10>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://76737c2c7d62:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.4.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>ML Pipelines Tutorial</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":63}]},{"cell_type":"markdown","source":["# **ML Pipelines API**\n","* [ML Pipelines](https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html#pipeline-apis) is a set of high-level APIs built on top of [Spark DataFrames](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html) to help you organize machine learning pipelines.\n","* An ML Pipeline is composed of a series of stages inlcuding Transformers and Estimators.\n","* This tutorial is based on [Learning Spark, 2nd Edition Book](https://www.oreilly.com/library/view/learning-spark-2nd/9781492050032/) (Chapter 10), and [Spark Programming Guide: ML Pipelines](https://spark.apache.org/docs/latest/ml-pipeline.html)."],"metadata":{"id":"P_lr1ZOdtP5U"}},{"cell_type":"markdown","source":["# Dataset\n","* You will use the San Francisco housing data set from [Inside\n","Airbnb](http://insideairbnb.com/get-the-data/).\n","\n","* A cleaned version of this data is provided in databricks-datasets: `sf-airbnb-clean.parquet`\n","\n","* The goal is to build a model to predict the price per night for a rental property.\n","\n","* This is a regression problem, because price is a continuous variable.\n","\n"],"metadata":{"id":"ceOVcwYUYpHc"}},{"cell_type":"code","source":["# set the file path depending on your environment\n","filePath = \"/content/drive/MyDrive/sample_data/learning-spark-v2/sf-airbnb/sf-airbnb-clean.parquet\""],"metadata":{"id":"O8fh1-kkePNK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["airbnbDF = spark.read.parquet(dataPath)"],"metadata":{"id":"G6PieKSmYoV6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["airbnbDF.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x4x3jbeqxGKe","executionInfo":{"status":"ok","timestamp":1691991482866,"user_tz":-480,"elapsed":5,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"85f5168e-55ee-4f68-a33d-8bf50c2c0a7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- host_is_superhost: string (nullable = true)\n"," |-- cancellation_policy: string (nullable = true)\n"," |-- instant_bookable: string (nullable = true)\n"," |-- host_total_listings_count: double (nullable = true)\n"," |-- neighbourhood_cleansed: string (nullable = true)\n"," |-- latitude: double (nullable = true)\n"," |-- longitude: double (nullable = true)\n"," |-- property_type: string (nullable = true)\n"," |-- room_type: string (nullable = true)\n"," |-- accommodates: double (nullable = true)\n"," |-- bathrooms: double (nullable = true)\n"," |-- bedrooms: double (nullable = true)\n"," |-- beds: double (nullable = true)\n"," |-- bed_type: string (nullable = true)\n"," |-- minimum_nights: double (nullable = true)\n"," |-- number_of_reviews: double (nullable = true)\n"," |-- review_scores_rating: double (nullable = true)\n"," |-- review_scores_accuracy: double (nullable = true)\n"," |-- review_scores_cleanliness: double (nullable = true)\n"," |-- review_scores_checkin: double (nullable = true)\n"," |-- review_scores_communication: double (nullable = true)\n"," |-- review_scores_location: double (nullable = true)\n"," |-- review_scores_value: double (nullable = true)\n"," |-- price: double (nullable = true)\n"," |-- bedrooms_na: double (nullable = true)\n"," |-- bathrooms_na: double (nullable = true)\n"," |-- beds_na: double (nullable = true)\n"," |-- review_scores_rating_na: double (nullable = true)\n"," |-- review_scores_accuracy_na: double (nullable = true)\n"," |-- review_scores_cleanliness_na: double (nullable = true)\n"," |-- review_scores_checkin_na: double (nullable = true)\n"," |-- review_scores_communication_na: double (nullable = true)\n"," |-- review_scores_location_na: double (nullable = true)\n"," |-- review_scores_value_na: double (nullable = true)\n","\n"]}]},{"cell_type":"code","source":["airbnbDF.show(5, truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tmEXda1TscVQ","executionInfo":{"status":"ok","timestamp":1691991486297,"user_tz":-480,"elapsed":604,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"4cb225fe-b096-4638-8509-30d1fd3a6f75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------------+---------------------------+----------------+-------------------------+----------------------+--------+----------+-------------+---------------+------------+---------+--------+----+--------+--------------+-----------------+--------------------+----------------------+-------------------------+---------------------+---------------------------+----------------------+-------------------+-----+-----------+------------+-------+-----------------------+-------------------------+----------------------------+------------------------+------------------------------+-------------------------+----------------------+\n","|host_is_superhost|cancellation_policy        |instant_bookable|host_total_listings_count|neighbourhood_cleansed|latitude|longitude |property_type|room_type      |accommodates|bathrooms|bedrooms|beds|bed_type|minimum_nights|number_of_reviews|review_scores_rating|review_scores_accuracy|review_scores_cleanliness|review_scores_checkin|review_scores_communication|review_scores_location|review_scores_value|price|bedrooms_na|bathrooms_na|beds_na|review_scores_rating_na|review_scores_accuracy_na|review_scores_cleanliness_na|review_scores_checkin_na|review_scores_communication_na|review_scores_location_na|review_scores_value_na|\n","+-----------------+---------------------------+----------------+-------------------------+----------------------+--------+----------+-------------+---------------+------------+---------+--------+----+--------+--------------+-----------------+--------------------+----------------------+-------------------------+---------------------+---------------------------+----------------------+-------------------+-----+-----------+------------+-------+-----------------------+-------------------------+----------------------------+------------------------+------------------------------+-------------------------+----------------------+\n","|t                |moderate                   |t               |1.0                      |Western Addition      |37.76931|-122.43386|Apartment    |Entire home/apt|3.0         |1.0      |1.0     |2.0 |Real Bed|1.0           |180.0            |97.0                |10.0                  |10.0                     |10.0                 |10.0                       |10.0                  |10.0               |170.0|0.0        |0.0         |0.0    |0.0                    |0.0                      |0.0                         |0.0                     |0.0                           |0.0                      |0.0                   |\n","|f                |strict_14_with_grace_period|f               |2.0                      |Bernal Heights        |37.74511|-122.42102|Apartment    |Entire home/apt|5.0         |1.0      |2.0     |3.0 |Real Bed|30.0          |111.0            |98.0                |10.0                  |10.0                     |10.0                 |10.0                       |10.0                  |9.0                |235.0|0.0        |0.0         |0.0    |0.0                    |0.0                      |0.0                         |0.0                     |0.0                           |0.0                      |0.0                   |\n","|f                |strict_14_with_grace_period|f               |10.0                     |Haight Ashbury        |37.76669|-122.4525 |Apartment    |Private room   |2.0         |4.0      |1.0     |1.0 |Real Bed|32.0          |17.0             |85.0                |8.0                   |8.0                      |9.0                  |9.0                        |9.0                   |8.0                |65.0 |0.0        |0.0         |0.0    |0.0                    |0.0                      |0.0                         |0.0                     |0.0                           |0.0                      |0.0                   |\n","|f                |strict_14_with_grace_period|f               |10.0                     |Haight Ashbury        |37.76487|-122.45183|Apartment    |Private room   |2.0         |4.0      |1.0     |1.0 |Real Bed|32.0          |8.0              |93.0                |9.0                   |9.0                      |10.0                 |10.0                       |9.0                   |9.0                |65.0 |0.0        |0.0         |0.0    |0.0                    |0.0                      |0.0                         |0.0                     |0.0                           |0.0                      |0.0                   |\n","|f                |strict_14_with_grace_period|f               |2.0                      |Western Addition      |37.77525|-122.43637|House        |Entire home/apt|5.0         |1.5      |2.0     |2.0 |Real Bed|7.0           |27.0             |97.0                |10.0                  |10.0                     |10.0                 |10.0                       |10.0                  |9.0                |785.0|0.0        |0.0         |0.0    |0.0                    |0.0                      |0.0                         |0.0                     |0.0                           |0.0                      |0.0                   |\n","+-----------------+---------------------------+----------------+-------------------------+----------------------+--------+----------+-------------+---------------+------------+---------+--------+----+--------+--------------+-----------------+--------------------+----------------------+-------------------------+---------------------+---------------------------+----------------------+-------------------+-----+-----------+------------+-------+-----------------------+-------------------------+----------------------------+------------------------+------------------------------+-------------------------+----------------------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"markdown","source":["# Creating Training and Test Data Sets\n","\n","* [randomSplit](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.randomSplit.html):  randomly split a DataFrame into two sets: for instance, training (80%) and test (20%)."],"metadata":{"id":"xoC97oW6ZsVU"}},{"cell_type":"code","source":["trainDF, testDF = airbnbDF.randomSplit([.8, .2], seed=42)\n","\n","print(f\"\"\"There are {trainDF.count()} rows in the training set, and {testDF.count()} in the test set\"\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T3tfsVHxZO7t","executionInfo":{"status":"ok","timestamp":1691991490648,"user_tz":-480,"elapsed":1558,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"3ba21583-410a-4741-f435-b1c45a52b8e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 5780 rows in the training set, and 1366 in the test set\n"]}]},{"cell_type":"markdown","source":["* Would the output of the split be the same in case you repartition your DataFrame?\n","\n"],"metadata":{"id":"o3361eOGEZWu"}},{"cell_type":"markdown","source":["#Preparing Features with Transformers\n","* Linear regression requires that all the input features are contained within a single vector in your\n","DataFrame.\n","\n","* [VectorAssembler](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.VectorAssembler.html): a Transformer that merges multiple columns into a vector column. Use it to put all of the features into a single vector.\n","\n","\n"],"metadata":{"id":"o_lfz8frZyrC"}},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\n","\n","#create the transformer\n","#inputCols: as an example, we only add some columns (should be numeric)\n","vecAssembler = VectorAssembler(inputCols=[\"accommodates\",\"bathrooms\",\"bedrooms\",\"beds\",\"minimum_nights\"],\n","                               outputCol=\"features\")\n","\n","#call the transform method, and select only the features column & the target column (price)\n","vecTrainDF = vecAssembler.transform(trainDF).select(\"features\", \"price\")\n","\n","vecTrainDF.show(5, False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MNsdcdz9Z8ub","executionInfo":{"status":"ok","timestamp":1691991501553,"user_tz":-480,"elapsed":1070,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"fa59212d-914b-4066-f04c-c8132f85b9be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------------------+-----+\n","|features               |price|\n","+-----------------------+-----+\n","|[2.0,1.0,1.0,1.0,1.0]  |200.0|\n","|[3.0,1.0,1.0,1.0,90.0] |130.0|\n","|[4.0,1.0,1.0,3.0,1.0]  |95.0 |\n","|[2.0,1.0,1.0,1.0,180.0]|250.0|\n","|[6.0,3.0,3.0,3.0,30.0] |250.0|\n","+-----------------------+-----+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","source":["#you can see the features column is represented as a vector\n","vecTrainDF.take(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AqVdjIaBMPMq","executionInfo":{"status":"ok","timestamp":1691991508230,"user_tz":-480,"elapsed":1121,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"09cdd4a2-8cb4-4ba6-edad-aece638f6d7c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(features=DenseVector([2.0, 1.0, 1.0, 1.0, 1.0]), price=200.0),\n"," Row(features=DenseVector([3.0, 1.0, 1.0, 1.0, 90.0]), price=130.0),\n"," Row(features=DenseVector([4.0, 1.0, 1.0, 3.0, 1.0]), price=95.0),\n"," Row(features=DenseVector([2.0, 1.0, 1.0, 1.0, 180.0]), price=250.0),\n"," Row(features=DenseVector([6.0, 3.0, 3.0, 3.0, 30.0]), price=250.0)]"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["# Using Estimators to Build Models"],"metadata":{"id":"aLr-8rMiZ76a"}},{"cell_type":"markdown","source":["* [LinearRegression](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html) is\n","a type of estimator—it takes in a `DataFrame` and returns a [LinearRegressionModel](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegressionModel.html)."],"metadata":{"id":"7wxRC1qFT7bK"}},{"cell_type":"code","source":["from pyspark.ml.regression import LinearRegression\n","\n","lr1 = LinearRegression(featuresCol=\"features\", labelCol=\"price\")\n","\n","lrModel1 = lr1.fit(vecTrainDF)\n","lrModel1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yGQII4stZ_Mo","executionInfo":{"status":"ok","timestamp":1691991517727,"user_tz":-480,"elapsed":2198,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"1aa5b23d-3e2f-4907-8281-6abda731867b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearRegressionModel: uid=LinearRegression_ad66f3cd1a8b, numFeatures=5"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["* The output of an estimator's fit() method is a transformer. Once the\n","estimator has learned the parameters, the transformer can apply these parameters to\n","new data points to generate predictions."],"metadata":{"id":"xXTmY3tJVLoA"}},{"cell_type":"code","source":["# the learned parameters\n","print(\"coefficients:\", lrModel1.coefficients)\n","print(\"intercept:\", lrModel1.intercept)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TugoAzgJaBYW","executionInfo":{"status":"ok","timestamp":1691991522284,"user_tz":-480,"elapsed":425,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"403fcec7-5a98-4354-804d-dece41854cd3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["coefficients: [41.08785094623204,12.413821017644553,64.34316258394297,-10.377255092373604,-0.7445442235199358]\n","intercept: 9.076028961598917\n"]}]},{"cell_type":"markdown","source":["# Creating a Pipeline\n","\n","* A [`Pipeline`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.Pipeline.html?highlight=pipeline#pyspark.ml.Pipeline) is an estimator, whereas a [`PipelineModel`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.PipelineModel.html?highlight=pipelinemodel#pyspark.ml.PipelineModel) —fitted Pipelines— is a transformer.\n","\n","* You specify the stages you want your data to\n","pass through, in order, and Spark takes care of the processing for you.\n"],"metadata":{"id":"nAjZQppeMTs8"}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\n","\n","lrPipeline1 = Pipeline(stages=[vecAssembler, lr1])\n","\n","lrPipelineModel1 = lrPipeline1.fit(trainDF)"],"metadata":{"id":"9LX7D8gkMWii"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* lrPipelineModel is a transformer. You can now apply it to your test data:"],"metadata":{"id":"i8h7hGpvMYeT"}},{"cell_type":"code","source":["lrPredDF1 = lrPipelineModel1.transform(testDF)"],"metadata":{"id":"rI7q1VVWMaZ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#two new columns should appear: features vector and predictions\n","lrPredDF1.show(5, truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZN8nZYMGSAAT","executionInfo":{"status":"ok","timestamp":1691991536968,"user_tz":-480,"elapsed":441,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"b86c6517-3b39-4dac-a17d-1925467e9ac8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------------+-------------------+----------------+-------------------------+----------------------+--------+----------+-------------+---------------+------------+---------+--------+----+--------+--------------+-----------------+--------------------+----------------------+-------------------------+---------------------+---------------------------+----------------------+-------------------+-----+-----------+------------+-------+-----------------------+-------------------------+----------------------------+------------------------+------------------------------+-------------------------+----------------------+----------------------+------------------+\n","|host_is_superhost|cancellation_policy|instant_bookable|host_total_listings_count|neighbourhood_cleansed|latitude|longitude |property_type|room_type      |accommodates|bathrooms|bedrooms|beds|bed_type|minimum_nights|number_of_reviews|review_scores_rating|review_scores_accuracy|review_scores_cleanliness|review_scores_checkin|review_scores_communication|review_scores_location|review_scores_value|price|bedrooms_na|bathrooms_na|beds_na|review_scores_rating_na|review_scores_accuracy_na|review_scores_cleanliness_na|review_scores_checkin_na|review_scores_communication_na|review_scores_location_na|review_scores_value_na|features              |prediction        |\n","+-----------------+-------------------+----------------+-------------------------+----------------------+--------+----------+-------------+---------------+------------+---------+--------+----+--------+--------------+-----------------+--------------------+----------------------+-------------------------+---------------------+---------------------------+----------------------+-------------------+-----+-----------+------------+-------+-----------------------+-------------------------+----------------------------+------------------------+------------------------------+-------------------------+----------------------+----------------------+------------------+\n","|f                |flexible           |f               |1.0                      |Bayview               |37.72001|-122.39249|House        |Entire home/apt|2.0         |1.0      |1.0     |1.0 |Real Bed|2.0           |128.0            |97.0                |10.0                  |10.0                     |10.0                 |10.0                       |9.0                   |10.0               |85.0 |0.0        |0.0         |0.0    |0.0                    |0.0                      |0.0                         |0.0                     |0.0                           |0.0                      |0.0                   |[2.0,1.0,1.0,1.0,2.0] |156.14237091623704|\n","|f                |flexible           |f               |1.0                      |Bayview               |37.7325 |-122.39221|House        |Private room   |1.0         |1.0      |1.0     |1.0 |Real Bed|31.0          |0.0              |98.0                |10.0                  |10.0                     |10.0                 |10.0                       |10.0                  |10.0               |45.0 |0.0        |0.0         |0.0    |1.0                    |1.0                      |1.0                         |1.0                     |1.0                           |1.0                      |1.0                   |[1.0,1.0,1.0,1.0,31.0]|93.46273748792687 |\n","|f                |flexible           |f               |1.0                      |Bayview               |37.73555|-122.39779|House        |Private room   |1.0         |1.0      |1.0     |1.0 |Real Bed|30.0          |0.0              |98.0                |10.0                  |10.0                     |10.0                 |10.0                       |10.0                  |10.0               |70.0 |0.0        |0.0         |0.0    |1.0                    |1.0                      |1.0                         |1.0                     |1.0                           |1.0                      |1.0                   |[1.0,1.0,1.0,1.0,30.0]|94.20728171144681 |\n","|f                |flexible           |f               |1.0                      |Bernal Heights        |37.73905|-122.41269|Apartment    |Private room   |1.0         |1.0      |1.0     |1.0 |Real Bed|30.0          |1.0              |80.0                |10.0                  |8.0                      |10.0                 |10.0                       |8.0                   |10.0               |128.0|0.0        |0.0         |0.0    |0.0                    |0.0                      |0.0                         |0.0                     |0.0                           |0.0                      |0.0                   |[1.0,1.0,1.0,1.0,30.0]|94.20728171144681 |\n","|f                |flexible           |f               |1.0                      |Bernal Heights        |37.74473|-122.41516|House        |Private room   |1.0         |1.0      |1.0     |1.0 |Real Bed|1.0           |3.0              |100.0               |10.0                  |10.0                     |10.0                 |10.0                       |10.0                  |10.0               |159.0|0.0        |0.0         |0.0    |0.0                    |0.0                      |0.0                         |0.0                     |0.0                           |0.0                      |0.0                   |[1.0,1.0,1.0,1.0,1.0] |115.79906419352494|\n","+-----------------+-------------------+----------------+-------------------------+----------------------+--------+----------+-------------+---------------+------------+---------+--------+----+--------+--------------+-----------------+--------------------+----------------------+-------------------------+---------------------+---------------------------+----------------------+-------------------+-----+-----------+------------+-------+-----------------------+-------------------------+----------------------------+------------------------+------------------------------+-------------------------+----------------------+----------------------+------------------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","source":["#you may select only the columns related to your case\n","lrPredDF1.select(\"features\", \"price\", \"prediction\").show(5, truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V8wD4hDsSJM6","executionInfo":{"status":"ok","timestamp":1691991539898,"user_tz":-480,"elapsed":420,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"d5271e29-c9cf-4345-fd47-8ee18a563d85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------------+-----+------------------+\n","|features              |price|prediction        |\n","+----------------------+-----+------------------+\n","|[2.0,1.0,1.0,1.0,2.0] |85.0 |156.14237091623704|\n","|[1.0,1.0,1.0,1.0,31.0]|45.0 |93.46273748792687 |\n","|[1.0,1.0,1.0,1.0,30.0]|70.0 |94.20728171144681 |\n","|[1.0,1.0,1.0,1.0,30.0]|128.0|94.20728171144681 |\n","|[1.0,1.0,1.0,1.0,1.0] |159.0|115.79906419352494|\n","+----------------------+-----+------------------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"markdown","source":["# One-hot encoding\n","\n","* To convert categorical values into numeric values, you can use a technique called one-hot encoding (OHE).\n","\n","* A common approach to do one-hot encoding in Spark is\n","to use [StringIndexer](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.StringIndexer.html) and [OneHotEncoder](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.OneHotEncoder.html).\n","* The first step is to\n","apply the StringIndexer estimator to convert categorical values into category indices.\n","These category indices are ordered by label frequencies, so the most frequent\n","label gets index 0, which provides us with reproducible results across various runs of\n","the same data.\n","* Then, you pass those category indices as input to the\n","OneHotEncoder which maps a column of category indices to a column of binary vectors.\n","* Spark internally uses a [SparseVector](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.linalg.SparseVector.html) when\n","the majority of the entries are 0, as is often the case after OHE, so it does not waste\n","space storing 0 values."],"metadata":{"id":"XGSLn2GRIbfU"}},{"cell_type":"code","source":["from pyspark.ml.feature import  StringIndexer, OneHotEncoder\n","\n","#get list of columns with string data type\n","categoricalCols = [field for (field, dataType) in trainDF.dtypes\n","                  if dataType == \"string\"]\n","categoricalCols"],"metadata":{"id":"p5t9KxyHIhst","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691991544831,"user_tz":-480,"elapsed":439,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"fd321f88-3677-4ed6-8a97-e699cb9712c9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['host_is_superhost',\n"," 'cancellation_policy',\n"," 'instant_bookable',\n"," 'neighbourhood_cleansed',\n"," 'property_type',\n"," 'room_type',\n"," 'bed_type']"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["#names for StringIndexer's output columns\n","indexOutputCols = [x + \"Index\" for x in categoricalCols]\n","\n","#create your StringIndexer\n","stringIndexer = StringIndexer(inputCols=categoricalCols, outputCols=indexOutputCols, handleInvalid=\"skip\")"],"metadata":{"id":"pyVAvq1GYWJT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* `handleInvalid`: specifies how you want to handle new categories that may appear in the test data set.\n","\n","* The options are `skip` (filter out rows with invalid data), `error` (throw an error), or `keep` (put invalid\n","data in a special additional bucket, at index `numLabels`)."],"metadata":{"id":"orzz9pM-SqL-"}},{"cell_type":"code","source":["#names for OneHotEncoder's output columns\n","oheOutputCols = [x + \"OHE\" for x in categoricalCols]\n","\n","#create your OneHotEncoder\n","oheEncoder = OneHotEncoder(inputCols=indexOutputCols, outputCols=oheOutputCols)"],"metadata":{"id":"YLIUsiE0TIm3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#get list of numeric columns\n","numericCols = [field for (field, dataType) in trainDF.dtypes\n","              if ((dataType == \"double\") & (field != \"price\"))]\n","\n","assemblerInputs = oheOutputCols + numericCols\n","\n","assemblerInputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7oYEhSgeMu0C","executionInfo":{"status":"ok","timestamp":1691999284510,"user_tz":-480,"elapsed":9,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"0d5dbaf2-e12a-48ca-8324-df5bea980187"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['host_is_superhostOHE',\n"," 'cancellation_policyOHE',\n"," 'instant_bookableOHE',\n"," 'neighbourhood_cleansedOHE',\n"," 'property_typeOHE',\n"," 'room_typeOHE',\n"," 'bed_typeOHE',\n"," 'host_total_listings_count',\n"," 'latitude',\n"," 'longitude',\n"," 'accommodates',\n"," 'bathrooms',\n"," 'bedrooms',\n"," 'beds',\n"," 'minimum_nights',\n"," 'number_of_reviews',\n"," 'review_scores_rating',\n"," 'review_scores_accuracy',\n"," 'review_scores_cleanliness',\n"," 'review_scores_checkin',\n"," 'review_scores_communication',\n"," 'review_scores_location',\n"," 'review_scores_value',\n"," 'bedrooms_na',\n"," 'bathrooms_na',\n"," 'beds_na',\n"," 'review_scores_rating_na',\n"," 'review_scores_accuracy_na',\n"," 'review_scores_cleanliness_na',\n"," 'review_scores_checkin_na',\n"," 'review_scores_communication_na',\n"," 'review_scores_location_na',\n"," 'review_scores_value_na']"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["#create your vectorAssembler with the new list of numeric input columns\n","vecAssembler = VectorAssembler(inputCols = assemblerInputs, outputCol = \"features\")\n","\n","#Now you can add a linear regression model using all of the features as input.\n","lr2 = LinearRegression(labelCol=\"price\", featuresCol=\"features\")\n","\n","#create a pipeline with the four stages\n","lrPipeline2 = Pipeline(stages = [stringIndexer, oheEncoder, vecAssembler, lr2])\n","\n","lrPipelineModel2 = lrPipeline2.fit(trainDF)\n","\n","predDF2 = lrPipelineModel2.transform(testDF)\n","predDF2.select(\"features\", \"price\", \"prediction\").show(5, False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EjeZCK7GUGpo","executionInfo":{"status":"ok","timestamp":1691991563515,"user_tz":-480,"elapsed":6881,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"0af63be8-649d-45a1-e1dc-aa406585cfa7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+------------------+\n","|features                                                                                                                                                                                                                            |price|prediction        |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+------------------+\n","|(98,[0,3,6,22,43,66,68,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,37.72001,-122.39249,2.0,1.0,1.0,1.0,2.0,128.0,97.0,10.0,10.0,10.0,10.0,9.0,10.0])                                          |85.0 |55.7117331960344  |\n","|(98,[0,3,6,22,43,67,68,72,73,74,75,76,77,78,79,81,82,83,84,85,86,87,91,92,93,94,95,96,97],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,37.7325,-122.39221,1.0,1.0,1.0,1.0,31.0,98.0,10.0,10.0,10.0,10.0,10.0,10.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]) |45.0 |23.11121524248665 |\n","|(98,[0,3,6,22,43,67,68,72,73,74,75,76,77,78,79,81,82,83,84,85,86,87,91,92,93,94,95,96,97],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,37.73555,-122.39779,1.0,1.0,1.0,1.0,30.0,98.0,10.0,10.0,10.0,10.0,10.0,10.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|70.0 |27.644339230358128|\n","|(98,[0,3,6,12,42,67,68,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,37.73905,-122.41269,1.0,1.0,1.0,1.0,30.0,1.0,80.0,10.0,8.0,10.0,10.0,8.0,10.0])                                            |128.0|-92.40433634418105|\n","|(98,[0,3,6,12,43,67,68,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,37.74473,-122.41516,1.0,1.0,1.0,1.0,1.0,3.0,100.0,10.0,10.0,10.0,10.0,10.0,10.0])                                          |159.0|94.84679937388546 |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+------------------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"markdown","source":["* As you can see, the features column is represented as a SparseVector. There are 98\n","features after one-hot encoding, followed by the nonzero indices and then the values\n","themselves."],"metadata":{"id":"uSmY_8OeU5Xk"}},{"cell_type":"markdown","source":["# Evaluating Models\n","* [RegressionEvaluator](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.RegressionEvaluator.html)"],"metadata":{"id":"s9I7oMFnMbmy"}},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\n","\n","regressionEvaluator = RegressionEvaluator(predictionCol=\"prediction\",\n","                                          labelCol=\"price\",\n","                                          metricName=\"rmse\")\n","\n","rmse = regressionEvaluator.evaluate(predDF2)\n","rmse"],"metadata":{"id":"G7mYYXRzWl3g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691991567663,"user_tz":-480,"elapsed":1194,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"e1af4c38-8e3f-44f1-d599-4368a3194263"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["220.6659096945873"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["# use another metric with the same evaluator: R-squared\n","r2_metric = regressionEvaluator.setMetricName(\"r2\").evaluate(predDF2)\n","r2_metric"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nJxrSbwBXo4E","executionInfo":{"status":"ok","timestamp":1691991570664,"user_tz":-480,"elapsed":538,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"920357d0-4a73-4ad4-bc8f-93e11c375790"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.15965119209930734"]},"metadata":{},"execution_count":55}]},{"cell_type":"markdown","source":["# Saving and Loading Pipeline Models\n"],"metadata":{"id":"Pe06e0Lpb8OP"}},{"cell_type":"code","source":["pipelinePath = \"/tmp/lrPipelineModel2\"\n","lrPipelineModel2.save(pipelinePath)"],"metadata":{"id":"MwbKg_UKX0Al"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* You can later load this model and use it to predict on new data again."],"metadata":{"id":"cQuyDnCzYcB5"}},{"cell_type":"code","source":["from pyspark.ml import PipelineModel\n","savedPipelineModel = PipelineModel.load(pipelinePath)"],"metadata":{"id":"BFtk2j6hYc39"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["savedPipelineModel.stages"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cKsF6osHgY56","executionInfo":{"status":"ok","timestamp":1691999251024,"user_tz":-480,"elapsed":502,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"5891f4f3-8135-4bcd-c908-d7336e513c75"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[StringIndexerModel: uid=StringIndexer_6189856236c8, handleInvalid=skip, numInputCols=7, numOutputCols=7,\n"," OneHotEncoderModel: uid=OneHotEncoder_57c14dabf4fb, dropLast=true, handleInvalid=error, numInputCols=7, numOutputCols=7,\n"," VectorAssembler_f5b4b547a894,\n"," LinearRegressionModel: uid=LinearRegression_c90678311099, numFeatures=98]"]},"metadata":{},"execution_count":65}]},{"cell_type":"markdown","source":["# Pipeline with Decision Trees\n","* [DecisionTreeRegressor](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.DecisionTreeRegressor.html)\n","* [DecisionTreeRegressionModel](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.DecisionTreeRegressionModel.html)\n"],"metadata":{"id":"DIez-x69KFQz"}},{"cell_type":"code","source":["from pyspark.ml.regression import DecisionTreeRegressor\n","\n","dt = DecisionTreeRegressor(labelCol=\"price\")\n","\n","# Filter for just numeric columns (and exclude price, our label)\n","numericCols = [field for (field, dataType) in trainDF.dtypes\n","              if ((dataType == \"double\") & (field != \"price\"))]\n","\n","# Combine output of StringIndexer defined above and numeric columns\n","assemblerInputs = indexOutputCols + numericCols\n","vecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")"],"metadata":{"id":"dAiwIL8UKKzx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create pipeline\n","pipeline = Pipeline(stages=[stringIndexer, vecAssembler, dt])\n","\n","#fit the pipeline\n","pipelineModel = pipeline.fit(trainDF) # This line should error"],"metadata":{"id":"R4gHkKUpH9z6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# in this example, we reset the maxbin to solve the issue\n","dt.setMaxBins(40)\n","pipelineModel = pipeline.fit(trainDF)"],"metadata":{"id":"mMB5HWyqKYsL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#now, we can extract the if-then-else rules learned by the decision tree\n","dtModel = pipelineModel.stages[-1]\n","print(dtModel.toDebugString)"],"metadata":{"id":"m0LUYLi5KdWs","colab":{"base_uri":"https://localhost:8080/","height":191},"executionInfo":{"status":"ok","timestamp":1692001669990,"user_tz":-480,"elapsed":633,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"a1b088c1-76c9-42b6-9e25-02cb7031d4f9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'DecisionTreeRegressionModel: uid=DecisionTreeRegressor_6ea45801baec, depth=5, numNodes=47, numFeatures=33\\n  If (feature 12 <= 2.5)\\n   If (feature 12 <= 1.5)\\n    If (feature 5 in {1.0,2.0})\\n     If (feature 4 in {0.0,1.0,3.0,5.0,9.0,10.0,11.0,13.0,14.0,16.0,18.0,24.0})\\n      If (feature 3 in {0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0})\\n       Predict: 104.23992784125075\\n      Else (feature 3 not in {0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0})\\n       Predict: 250.7111111111111\\n     Else (feature 4 not in {0.0,1.0,3.0,5.0,9.0,10.0,11.0,13.0,14.0,16.0,18.0,24.0})\\n      If (feature 3 in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,27.0,33.0,35.0})\\n       Predict: 151.94179894179894\\n      Else (feature 3 not in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,27.0,33.0,35.0})\\n       Predict: 245.8507462686567\\n    Else (feature 5 not in {1.0,2.0})\\n     If (feature 3 in {1.0,5.0,6.0,7.0,8.0,9.0,11.0,13.0,15.0,16.0,17.0,19.0,22.0,23.0,24.0,25.0,26.0,28.0,29.0,30.0,33.0})\\n      If (feature 3 in {5.0,8.0,13.0,15.0,16.0,19.0,22.0,23.0,24.0,25.0,28.0,30.0,33.0})\\n       Predict: 131.96658097686375\\n      Else (feature 3 not in {5.0,8.0,13.0,15.0,16.0,19.0,22.0,23.0,24.0,25.0,28.0,30.0,33.0})\\n       Predict: 164.19959266802445\\n     Else (feature 3 not in {1.0,5.0,6.0,7.0,8.0,9.0,11.0,13.0,15.0,16.0,17.0,19.0,22.0,23.0,24.0,25.0,26.0,28.0,29.0,30.0,33.0})\\n      If (feature 10 <= 6.5)\\n       Predict: 205.5814889336016\\n      Else (feature 10 > 6.5)\\n       Predict: 841.6666666666666\\n   Else (feature 12 > 1.5)\\n    If (feature 13 <= 4.5)\\n     If (feature 3 in {0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,15.0,16.0,17.0,18.0,19.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,33.0,34.0})\\n      If (feature 14 <= 26.5)\\n       Predict: 290.8357933579336\\n      Else (feature 14 > 26.5)\\n       Predict: 214.04819277108433\\n     Else (feature 3 not in {0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,15.0,16.0,17.0,18.0,19.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,33.0,34.0})\\n      If (feature 14 <= 3.5)\\n       Predict: 741.64\\n      Else (feature 14 > 3.5)\\n       Predict: 309.03921568627453\\n    Else (feature 13 > 4.5)\\n     If (feature 15 <= 0.5)\\n      If (feature 2 in {1.0})\\n       Predict: 300.0\\n      Else (feature 2 not in {1.0})\\n       Predict: 10000.0\\n     Else (feature 15 > 0.5)\\n      If (feature 3 in {1.0,4.0,5.0,7.0,8.0,19.0})\\n       Predict: 222.91666666666666\\n      Else (feature 3 not in {1.0,4.0,5.0,7.0,8.0,19.0})\\n       Predict: 398.0\\n  Else (feature 12 > 2.5)\\n   If (feature 1 in {0.0,1.0,2.0,3.0,4.0})\\n    If (feature 12 <= 5.5)\\n     If (feature 3 in {0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,10.0,11.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,21.0,22.0,23.0,24.0,25.0,26.0,28.0,29.0,30.0,33.0})\\n      If (feature 14 <= 7.5)\\n       Predict: 493.3795620437956\\n      Else (feature 14 > 7.5)\\n       Predict: 296.76666666666665\\n     Else (feature 3 not in {0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,10.0,11.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,21.0,22.0,23.0,24.0,25.0,26.0,28.0,29.0,30.0,33.0})\\n      If (feature 9 <= -122.411075)\\n       Predict: 722.96875\\n      Else (feature 9 > -122.411075)\\n       Predict: 2399.4\\n    Else (feature 12 > 5.5)\\n     If (feature 4 in {0.0,1.0,5.0,7.0})\\n      If (feature 3 in {0.0,3.0,6.0,25.0})\\n       Predict: 609.5\\n      Else (feature 3 not in {0.0,3.0,6.0,25.0})\\n       Predict: 1715.0\\n     Else (feature 4 not in {0.0,1.0,5.0,7.0})\\n      Predict: 8000.0\\n   Else (feature 1 not in {0.0,1.0,2.0,3.0,4.0})\\n    Predict: 8000.0\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":92}]},{"cell_type":"code","source":["#feature importance scores\n","import pandas as pd\n","\n","featureImp = pd.DataFrame(\n","list(zip(vecAssembler.getInputCols(), dtModel.featureImportances)),columns=[\"feature\", \"importance\"])\n","\n","featureImp.sort_values(by=\"importance\", ascending=False)"],"metadata":{"id":"d2d3xhYqeOSh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Pipeline with Random Forests\n","* [RandomForestRegressor](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.RandomForestRegressor.html)\n","* [DecisionTreeRegressionModel](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.DecisionTreeRegressionModel.html)"],"metadata":{"id":"o-Kx7pfW84Zf"}},{"cell_type":"code","source":["from pyspark.ml.regression import RandomForestRegressor\n","\n","rf = RandomForestRegressor(labelCol=\"price\", maxBins=40, seed=42)\n","\n","rfPipeline = Pipeline(stages = [stringIndexer, vecAssembler, rf])\n","\n","rfPipelineModel = rfPipeline.fit(trainDF)\n","\n","rfModel = rfPipelineModel.stages[-1]"],"metadata":{"id":"64hK7ZW386h7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rfModel.getNumTrees"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SUS2oeX4Jrke","executionInfo":{"status":"ok","timestamp":1692001870572,"user_tz":-480,"elapsed":563,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"bec52a87-e434-4876-868a-bc9970f56ca7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20"]},"metadata":{},"execution_count":100}]},{"cell_type":"code","source":["print(rfModel.trees)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nqualobUJ8rr","executionInfo":{"status":"ok","timestamp":1692001819644,"user_tz":-480,"elapsed":427,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"d4c7189a-a3b0-42ed-da38-cc790ac2f824"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DecisionTreeRegressionModel: uid=dtr_e06d844f60ca, depth=5, numNodes=61, numFeatures=33\n"]}]},{"cell_type":"code","source":["print(rfModel.toDebugString)"],"metadata":{"id":"DLlAYh6sLB4C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Tuning\n","* [pyspark.ml.tuning](https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html#tuning): tuning ML algorithms and Pipelines.\n","\n","* This includes cross-validation and other tools for hyperparameter tuning and model selection  as described in the [ML Tuning Official Guide](https://spark.apache.org/docs/latest/ml-tuning.html).\n","\n","* To perform a hyperparameter search in Spark, you need to: (1) define the estimator you want to evaluate, (2) specify which hyperparameters you want to vary, as well as their respective values, and (3) define an evaluator to specify which metric to use to compare the various\n","models and determine which one performed best.\n","* In this example, we take the RandomForest pipeline define dbefore as an estimator and we vary two parameters: maxDepth to be 2, 4, or 6 and [numTrees](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.RandomForestClassificationModel.html) to be 10 or 100.\n","\n","* This will give us a grid of 6 (3\n","x 2) different hyperparameter configurations in total:\n","\n","(maxDepth=2, numTrees=10)\n","\n","(maxDepth=2, numTrees=100)\n","\n","(maxDepth=4, numTrees=10)\n","\n","(maxDepth=4, numTrees=100)\n","\n","(maxDepth=6, numTrees=10)\n","\n","(maxDepth=6, numTrees=100)\n"],"metadata":{"id":"RYZetiTe-Nj6"}},{"cell_type":"markdown","source":["## ParamGridBuilder\n","*  [ParamGridBuilder](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.ParamGridBuilder.html): Specify which hyperparameters to tune, as well as their respective values."],"metadata":{"id":"FUYRldq9MzbM"}},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder\n","\n","paramGrid = (ParamGridBuilder()\n","            .addGrid(rf.maxDepth, [2, 4, 6])\n","            .addGrid(rf.numTrees, [10, 100])\n","            .build())"],"metadata":{"id":"p5SCXY_-AGap"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CrossValidator\n","\n","\n","* [CrossValidator](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html): perform k-fold cross-validation, evaluating each of the various\n","models.\n","* [CrossValidatorModel](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidatorModel.html)"],"metadata":{"id":"C1HEV2tz-kkD"}},{"cell_type":"code","source":["from pyspark.ml.tuning import CrossValidator\n","\n","cv = CrossValidator(estimator=rfPipeline,\n","                    evaluator=regressionEvaluator,\n","                    estimatorParamMaps=paramGrid,\n","                    numFolds=3,\n","                    seed=42)\n","\n","cvModel = cv.fit(trainDF)"],"metadata":{"id":"BjYJu2ZABP7W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","* Spark retrains your model on the entire training data set once it has\n","identified the optimal hyperparameter configuration\n","\n"],"metadata":{"id":"pyO4_hkOHQb4"}},{"cell_type":"code","source":["#To inspect the results of the cross-validator, you can take a look at the avgMetrics:\n","cvModel.avgMetrics"],"metadata":{"id":"3f_1lC3tBwa2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692004005181,"user_tz":-480,"elapsed":441,"user":{"displayName":"Salman Salloum","userId":"10391530522294962645"}},"outputId":"6f19fbc2-0004-4cef-ea57-64cda3c9dd55"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.1558541951669324,\n"," 0.18705504489990407,\n"," 0.1793619183973377,\n"," 0.22691576438617903,\n"," 0.1320026456261747,\n"," 0.2489339449458354]"]},"metadata":{},"execution_count":113}]},{"cell_type":"markdown","source":["\n","## Optimzing Pipelines\n","* [CrossValidator.parallelism](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html#pyspark.ml.tuning.CrossValidator.parallelism): determine the number of models to train in parallel.\n"],"metadata":{"id":"NEVoj34LJEBJ"}},{"cell_type":"code","source":["cvModel = cv.setParallelism(4).fit(trainDF)"],"metadata":{"id":"e_bVTQC-NDt-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* There's another trick we can use to speed up model training:\n","putting the cross-validator inside the pipeline (e.g., `Pipeline(stages=[..., cv])`\n","instead of putting the pipeline inside the cross-validator (e.g., `CrossValidator(esti\n","mator=pipeline, ...)`). As a result, StringIndexer (or any other estimator/transformer) will not be reevaluated each time a different model is trained during the cross validation process."],"metadata":{"id":"krsFauL_OG5C"}},{"cell_type":"code","source":["cv = CrossValidator(estimator=rf,\n","                    evaluator=regressionEvaluator,\n","                    estimatorParamMaps=paramGrid,\n","                    numFolds=3,\n","                    parallelism=4,\n","                    seed=42)\n","\n","pipeline = Pipeline(stages=[stringIndexer, vecAssembler, cv])\n","\n","pipelineModel = pipeline.fit(trainDF)"],"metadata":{"id":"atCAaNPiOHlT"},"execution_count":null,"outputs":[]}]}